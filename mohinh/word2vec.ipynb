{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang làm sạch dữ liệu từ CSV...\n"
     ]
    }
   ],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "model_embedding = word2vec.KeyedVectors.load('./word.model')\n",
    "\n",
    "word_labels = []\n",
    "max_seq = 200\n",
    "embedding_size = 128\n",
    "\n",
    "for word in model_embedding.vocab.keys():\n",
    "    word_labels.append(word)\n",
    "    \n",
    "def comment_embedding(comment):\n",
    "    matrix = np.zeros((max_seq, embedding_size))\n",
    "    words = comment.split()\n",
    "    lencmt = len(words)\n",
    "\n",
    "    for i in range(max_seq):\n",
    "        indexword = i % lencmt\n",
    "        if (max_seq - i < lencmt):\n",
    "            break\n",
    "        if(words[indexword] in words_label):\n",
    "            matrix[i] = model_embedding[words[indexword]]\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lưu vào tệp: ./path/to/data/tokenizer.txt\n"
     ]
    }
   ],
   "source": [
    "with open(file_tokenizer, 'w', encoding='utf-8') as f:\n",
    "    for line in df['cleaned_content']:\n",
    "        f.write(line + '\\n')\n",
    "print(f\"Dữ liệu đã được lưu vào tệp: {file_tokenizer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn lưu mô hình\n",
    "pathModelBin = './path/to/model/vnw2v.bin'  \n",
    "pathModelTxt = './path/to/model/vnw2v.txt' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu huấn luyện mô hình Word2Vec...\n",
      "Đã huấn luyện xong mô hình!\n",
      "Lưu mô hình nhị phân tại: ./path/to/model/vnw2v.bin\n",
      "Lưu mô hình văn bản tại: ./path/to/model/vnw2v.txt\n",
      "Đã lưu thành công cả hai định dạng mô hình!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Bắt đầu huấn luyện mô hình Word2Vec...\")\n",
    "\n",
    "    # Chuẩn bị dữ liệu\n",
    "    sentences = MySentences(file_tokenizer)\n",
    "\n",
    "    # Huấn luyện mô hình Word2Vec\n",
    "    model = gensim.models.Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=300,         # Kích thước vector embedding\n",
    "        window=10,               # Kích thước cửa sổ ngữ cảnh\n",
    "        min_count=10,            # Bỏ qua từ xuất hiện ít hơn 10 lần\n",
    "        sample=0.0001,           # Tần suất giảm mẫu\n",
    "        workers=4,               # Số luồng xử lý song song\n",
    "        sg=0,                    # CBOW (0) hoặc Skip-Gram (1)\n",
    "        negative=10,             # Số mẫu từ nhiễu (negative sampling)\n",
    "        cbow_mean=1,             # Trung bình vector ngữ cảnh\n",
    "        epochs=5                 # Số lần lặp qua toàn bộ dữ liệu\n",
    "    )\n",
    "\n",
    "    print(\"Đã huấn luyện xong mô hình!\")\n",
    "\n",
    "    # Lưu mô hình\n",
    "    print(f\"Lưu mô hình nhị phân tại: {pathModelBin}\")\n",
    "    model.wv.save_word2vec_format(pathModelBin, binary=True)\n",
    "\n",
    "    print(f\"Lưu mô hình văn bản tại: {pathModelTxt}\")\n",
    "    model.wv.save_word2vec_format(pathModelTxt, binary=False)\n",
    "\n",
    "    print(\"Đã lưu thành công cả hai định dạng mô hình!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
